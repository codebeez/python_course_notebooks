{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "We have a dataset that contains characteristics of the people on the titanic's first and last voyage. These characteristics. In addition we have the complete information of who survived and who perished in the disaster. It is our goal to load the data and get the data into shape for model fitting.\n",
    "\n",
    "## Handling missing data\n",
    "Missing data is one of the basic issues data can have. Many statistical models can not handle missing data and in most cases we need to either fill in or remove the records with missing values.\n",
    "\n",
    "## Cleaning data\n",
    "Data scientists spend most of their time cleaning up data and preprocessing it before feeding it to a model of choice. This preprocessing is also called feature engineering. We transform the raw data (people characteristics) into well defined features that our model van deal with.\n",
    "\n",
    "# 1 Imports, load data and first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = pd.read_csv('./data/train.csv')  # loads the CSV into a DataFrame with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()  # this prints the first 5 lines of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_data.describe())  # this prints basic statistics of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Impute missing data (preprocessing)\n",
    "Let take a look at the number of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_data.info())  # Wee see that Age and Cabin have a lot missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a strategy to deal with missing values we will fill them with values that do not alter the average of the age distribution. To this end we will 'impute' the missing age values with the mean of the 'Age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Age'] = titanic_data['Age'].fillna(titanic_data['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fill missing values in the port of embarkation\n",
    "The values in the 'Embarked' and their meaning are: C = Cherbourg, Q = Queenstown, S = Southampton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(titanic_data['Embarked'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "We see that the `'S'` Southhampton port is the port where most people embarked. Fill missing values in the 'Embarked' column with this most common port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Change the 'Embarked' column into a categorical variable (see the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create dummy variables for each of our categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(titanic_data['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Preprocessing\n",
    "We started preprocessing to impute the missing values in the 'Age' column. Now we will transform the raw data further to prepare it for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Convert sex to binary variable\n",
    "There are no missing values in the 'sex' column and back in 1912 everyone was either male or female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['binary_sex'] = titanic_data['Sex'] == 'male'  # make a new column with binary sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split the data in a train and test set\n",
    "To get an idea of how our model performs we need to train it with one part of our feature data and test it on. This is supported by the scikit-learn `train_test_split` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_data[['Age', 'binary_sex', 'Pclass']]\n",
    "y = titanic_data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Change the above code so that `X` contains our dummy variables (`dummies`) besides 'Age', 'binary_sex', 'Pclass'.\n",
    "Take a look at [pd.concat](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) nadake sure you do not append the dummies as new rows, but concatenate them along the column axis (axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Train the model on the training set\n",
    "Here we train a scikit-learn `DecisionTreeClassifier` on the training data sit, by calling the `fit` method of the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_classifier = tree.DecisionTreeClassifier(max_depth=3)\n",
    "decision_tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Predict the survival of the test set\n",
    "We predict the survival outcome for the persons in the test set by calling the `predict` method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = decision_tree_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Evaluate model performance\n",
    "Our model is a binary classifier; it predicts either survived or perished. Binary classifiers can be evaluated with a number of metrics, such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy', accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we can predict with a ~78% accuracy whether someone survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Fit the model with and without the Embarked variable, what is you conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
